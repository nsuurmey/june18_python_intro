{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Log Facies\n",
    "Actually, machine learning isn't that scary.  The Scikit Learn library provides a whole host of algorithms for different problems that can be activated simply.  This efficiency allows you to spend more time thinking about the results, whether they are valide, and how to optimize them.  \n",
    "\n",
    "In this exercise we have the standard log suite for a series of wells along with a facies classification.  We'll use the logs to train a model to predict these facies.\n",
    "\n",
    "#### Origin of Notebook\n",
    "This notebook was created with materials from Bendan Hall of Enthought: https://github.com/seg/2016-ml-contest/blob/master/Facies_classification.ipynb</br>\n",
    "And Matt Hall of Agile Scientific: https://github.com/agile-geoscience/xlines/blob/master/notebooks/04_Machine_learning.ipynb</br>\n",
    "Also, Alessandro Amato del Monte provided the code for the nice log views. Please see there notebooks for additional ideas and techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A word about the data.** This dataset is not, strictly speaking, open data. It has been shared by the Kansas Geological Survey for the purposes of the contest. That's why I'm not copying the data into this repository, but instead reading it from the web. We are working on making an open access version of this dataset. In the meantime, I'd appreciarte it if you didn't replicate the data anywhere. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load and Look at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file from web and look at first 5 rows\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/seg/2016-ml-contest/master/training_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard metrics for datatable\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data are in great shape, no missing values, consistent types, and at this level the data is within expected ranges.\n",
    "\n",
    "The next two code blocks are long and a bit technical for our exercise but they enable us to create beautiful plots.  The first block creates a color bar and label for Facies column, the second block creates a function for how we want the plot to look and builds it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1=sandstone  2=c_siltstone   3=f_siltstone \n",
    "# 4=marine_silt_shale 5=mudstone 6=wackestone 7=dolomite\n",
    "# 8=packstone 9=bafflestone\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00',\n",
    "       '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "facies_labels = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS',\n",
    "                 'WS', 'D','PS', 'BS']\n",
    "#facies_color_map is a dictionary that maps facies labels\n",
    "#to their respective colors\n",
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "\n",
    "def label_facies(row, labels):\n",
    "    return labels[ row['Facies'] -1]\n",
    "    \n",
    "df.loc[:,'FaciesLabels'] = df.apply(lambda row: label_facies(row, facies_labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_facies_log_plot(logs, facies_colors):\n",
    "    #make sure logs are sorted by depth\n",
    "    logs = logs.sort_values(by='Depth')\n",
    "    cmap_facies = colors.ListedColormap(\n",
    "            facies_colors[0:len(facies_colors)], 'indexed')\n",
    "    \n",
    "    ztop=logs.Depth.min(); zbot=logs.Depth.max()\n",
    "    \n",
    "    cluster=np.repeat(np.expand_dims(logs['Facies'].values,1), 100, 1)\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1, ncols=6, figsize=(8, 12))\n",
    "    ax[0].plot(logs.GR, logs.Depth, '-g')\n",
    "    ax[1].plot(logs.ILD_log10, logs.Depth, '-')\n",
    "    ax[2].plot(logs.DeltaPHI, logs.Depth, '-', color='0.5')\n",
    "    ax[3].plot(logs.PHIND, logs.Depth, '-', color='r')\n",
    "    ax[4].plot(logs.PE, logs.Depth, '-', color='black')\n",
    "    im=ax[5].imshow(cluster, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=9)\n",
    "    \n",
    "    divider = make_axes_locatable(ax[5])\n",
    "    cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "    cbar=plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label((17*' ').join([' SS ', 'CSiS', 'FSiS', \n",
    "                                'SiSh', ' MS ', ' WS ', ' D  ', \n",
    "                                ' PS ', ' BS ']))\n",
    "    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "    \n",
    "    for i in range(len(ax)-1):\n",
    "        ax[i].set_ylim(ztop,zbot)\n",
    "        ax[i].invert_yaxis()\n",
    "        ax[i].grid()\n",
    "        ax[i].locator_params(axis='x', nbins=3)\n",
    "    \n",
    "    ax[0].set_xlabel(\"GR\")\n",
    "    ax[0].set_xlim(logs.GR.min(),logs.GR.max())\n",
    "    ax[1].set_xlabel(\"ILD_log10\")\n",
    "    ax[1].set_xlim(logs.ILD_log10.min(),logs.ILD_log10.max())\n",
    "    ax[2].set_xlabel(\"DeltaPHI\")\n",
    "    ax[2].set_xlim(logs.DeltaPHI.min(),logs.DeltaPHI.max())\n",
    "    ax[3].set_xlabel(\"PHIND\")\n",
    "    ax[3].set_xlim(logs.PHIND.min(),logs.PHIND.max())\n",
    "    ax[4].set_xlabel(\"PE\")\n",
    "    ax[4].set_xlim(logs.PE.min(),logs.PE.max())\n",
    "    ax[5].set_xlabel('Facies')\n",
    "    \n",
    "    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
    "    ax[4].set_yticklabels([]); ax[5].set_yticklabels([])\n",
    "    ax[5].set_xticklabels([])\n",
    "    f.suptitle('Well: %s'%logs.iloc[0]['Well Name'], fontsize=14,y=0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function above we can plot any well from the data.  In the example below we've selected the Shrimplin well.  You can change the name of the well to look at additional plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_facies_log_plot(df[df['Well Name'] == 'SHRIMPLIN'],\n",
    "    facies_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next block creates a special set of plots called Paired Plots.  It will throw an error (red bar) at first but let it process and a clean set of plots should appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will throw an error message but be patient and it will work out.\n",
    "inline_rc = dict(mpl.rcParams)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "sns.pairplot(df.drop(['Well Name','Facies','Formation','Depth','NM_M','RELPOS'],axis=1),\n",
    "             hue='FaciesLabels', palette=facies_color_map,\n",
    "             hue_order=list(reversed(facies_labels)))\n",
    "\n",
    "#switch back to default matplotlib plot style\n",
    "mpl.rcParams.update(inline_rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on in this plot but the main thing is that there is no simple relationhsip between logs and facies but maybe a multidimensional analysis will be able to tease something out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Inputs, Labels and Splitting Data\n",
    "\n",
    "Now that we've had a look at the data its time to start building the model.  The next step is to get it into formats that scikit-learn will be able to read.  Following that we will split the data into training and testing datasets.  This will allow us to do a blind test on the data to insure that we aren't building a model too closely tied to the input data (i.e. overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data used to predict a facies.\n",
    "inputs = df[['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE']].values\n",
    "\n",
    "#Data is now a 2D array, here's an example\n",
    "inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facies label used to train the model\n",
    "labels = df.Facies.values\n",
    "\n",
    "#Data is now a 1D array, here's an example\n",
    "labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#75%/25% split of inputs and labels into a train and test groups for later cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels)\n",
    "\n",
    "# Double check that train and test have same number of samples.\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train and Evaluate Model\n",
    "Here we call the model and train it.  Its only three lines of code!  Three lines of code to machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classifier with set hyperparameters\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=10, n_jobs=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the accuracy of the model from the data withheld\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Optimize Model\n",
    "With the standard hyperparaters the model's accuracy is better than a coin flip, but not by much.\n",
    "\n",
    "__Experiment__ with different values hyperparaters _n_estimators_ and _n_jobs_ to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "n_estimators = 100\n",
    "n_jobs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=n_estimators, n_jobs=n_jobs, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5a. Evaluate the Model\n",
    "\n",
    "Optimization may need to go a level deeper to look at how each element is being predicted.  In this step we'll produce a prediciton and then evaluate the results using two different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a prediction based on last run of model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#generate accurracy score, should match from above\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approach to checking the accuracy of a model is to plot a confusion matrix where we can easily see which facies is being erroneous correlated with another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A fancier confusion matrix\n",
    "confm=confusion_matrix(y_test, y_pred)\n",
    "ax = sns.heatmap(confm, annot=True, fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate f1 score\n",
    "Classification_Report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "Classification_Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several steps that we could take to improve the model including:\n",
    "* Standarizing the data.\n",
    "* Factoring in relationships between facies (i.e. siltstones are often adjacent to sandstones)\n",
    "* Try a different model.  Different models may work better on different data types. \n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5b. Leaving a Well Out\n",
    "\n",
    "Another method of an evaluating a model is to leave out a significant segment of the population, in our case an entire well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a DataFrame with only one well and then separate the facies prediction\n",
    "blind = df[df['Well Name'] == 'SHANKLE']\n",
    "y_blind = blind['Facies'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select data for training\n",
    "blind_well_features = blind[['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE']].values\n",
    "\n",
    "#predict facies using the model from above\n",
    "y_pred = clf.predict(blind_well_features)\n",
    "\n",
    "#append prediction to blind DataFrame\n",
    "blind['Prediction']=y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another big code block that will create a new log visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_facies_plot(logs, compadre, facies_colors):\n",
    "    #make sure logs are sorted by depth\n",
    "    logs = logs.sort_values(by='Depth')\n",
    "    cmap_facies = colors.ListedColormap(\n",
    "            facies_colors[0:len(facies_colors)], 'indexed')\n",
    "    \n",
    "    ztop=logs.Depth.min(); zbot=logs.Depth.max()\n",
    "    \n",
    "    cluster1 = np.repeat(np.expand_dims(logs['Facies'].values,1), 100, 1)\n",
    "    cluster2 = np.repeat(np.expand_dims(logs[compadre].values,1), 100, 1)\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1, ncols=7, figsize=(9, 12))\n",
    "    ax[0].plot(logs.GR, logs.Depth, '-g')\n",
    "    ax[1].plot(logs.ILD_log10, logs.Depth, '-')\n",
    "    ax[2].plot(logs.DeltaPHI, logs.Depth, '-', color='0.5')\n",
    "    ax[3].plot(logs.PHIND, logs.Depth, '-', color='r')\n",
    "    ax[4].plot(logs.PE, logs.Depth, '-', color='black')\n",
    "    im1 = ax[5].imshow(cluster1, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=9)\n",
    "    im2 = ax[6].imshow(cluster2, interpolation='none', aspect='auto',\n",
    "                    cmap=cmap_facies,vmin=1,vmax=9)\n",
    "    \n",
    "    divider = make_axes_locatable(ax[6])\n",
    "    cax = divider.append_axes(\"right\", size=\"20%\", pad=0.05)\n",
    "    cbar=plt.colorbar(im2, cax=cax)\n",
    "    cbar.set_label((17*' ').join([' SS ', 'CSiS', 'FSiS', \n",
    "                                'SiSh', ' MS ', ' WS ', ' D  ', \n",
    "                                ' PS ', ' BS ']))\n",
    "    cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "    \n",
    "    for i in range(len(ax)-2):\n",
    "        ax[i].set_ylim(ztop,zbot)\n",
    "        ax[i].invert_yaxis()\n",
    "        ax[i].grid()\n",
    "        ax[i].locator_params(axis='x', nbins=3)\n",
    "    \n",
    "    ax[0].set_xlabel(\"GR\")\n",
    "    ax[0].set_xlim(logs.GR.min(),logs.GR.max())\n",
    "    ax[1].set_xlabel(\"ILD_log10\")\n",
    "    ax[1].set_xlim(logs.ILD_log10.min(),logs.ILD_log10.max())\n",
    "    ax[2].set_xlabel(\"DeltaPHI\")\n",
    "    ax[2].set_xlim(logs.DeltaPHI.min(),logs.DeltaPHI.max())\n",
    "    ax[3].set_xlabel(\"PHIND\")\n",
    "    ax[3].set_xlim(logs.PHIND.min(),logs.PHIND.max())\n",
    "    ax[4].set_xlabel(\"PE\")\n",
    "    ax[4].set_xlim(logs.PE.min(),logs.PE.max())\n",
    "    ax[5].set_xlabel('Facies')\n",
    "    ax[6].set_xlabel(compadre)\n",
    "    \n",
    "    ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([])\n",
    "    ax[4].set_yticklabels([]); ax[5].set_yticklabels([])\n",
    "    ax[5].set_xticklabels([])\n",
    "    ax[6].set_xticklabels([])\n",
    "    f.suptitle('Well: %s'%logs.iloc[0]['Well Name'], fontsize=14,y=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot well with logs, facies, and predicted facies\n",
    "compare_facies_plot(blind, 'Prediction', facies_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model appears to be doing well, getting the major blocks of facies but adding small pieces of noise periodically.  Let's build a confusion matrix to further investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for Shankle\n",
    "confm=confusion_matrix(y_pred, y_blind)\n",
    "ax = sns.heatmap(confm, annot=True, fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again much better than the original model.  Is it just the Shankle well?  Below is a list of the well names in the database.  Experiment with other wells in a blind test mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names of well in database\n",
    "list(df['Well Name'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
